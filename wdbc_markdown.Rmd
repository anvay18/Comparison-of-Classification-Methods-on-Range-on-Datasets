---
title: "Cancer Data Analysis"
author: "Anvay Ajit Karambelkar"
date: "18/09/2019"
output: html_document
---

R libraries

```{r}
library(knitr)
library(rmarkdown)
library(markdown)
library(caret)
```

This dataset contains attributes evaluated from images of breast mass. To solve the problem by classifying the instances into malignant and benign.

Importing cancer data.

```{r}
wdbc = read.csv('wdbc.csv')
Attributes <- c("radius", "texture", "perimeter", 
              "area", "smoothness", "compactness", 
              "concavity", "concave_points", "symmetry", 
              "fractal_dimension")
names(wdbc) <- c("id", "diagnosis", paste0(Attributes,"_mean"), paste0(Attributes,"_se"), paste0(Attributes,"_worst"))
```

The data is pre-processed by converting two categories of categorical variable 'diagnosis' into factors. Further they are divided into train and test set.

```{r}
wdbc$diagnosis = factor(wdbc$diagnosis, levels = c('M','B'), labels = c(0,1))
```

The data is partitioned based on 66% train-test split. i.e. 66% of the instances are considered for training set and rest of the them to test set.

```{r}
set.seed(24)
library(caTools)
split = sample.split(wdbc$diagnosis, SplitRatio = 2/3)
wdbc_train = subset(wdbc, split == T)
wdbc_test = subset(wdbc, split == F)
```

Both train and test sets are Standardizied in the follwing way.

```{r}
wdbc_train[, 3:32] = scale(wdbc_train[, 3:32])
wdbc_test[, 3:32] = scale(wdbc_test[, 3:32])
```

The classification methods selected for the analysis are Linear Discriminant analysis (LDA), Naive Bayes (NB), Support Vector Machine (Kernel SVM) and Random Forest (RF).

These four methods are trained on training data and then the outcomes are predicted on test data.






APPLYING LDA:

```{r}
library(MASS)
set.seed(24)
lda_wdbc = train(diagnosis ~ ., data=wdbc_train, method='lda')
```


The LDA algorithm is fitted to training dataset, further the observations are predicted on the test set.

```{r}
wdbc.lda_pred = predict(lda_wdbc, wdbc_test)
```

The model is evaluated based on the confusion matrix and other evalution metrics in the following way.

```{r}
confusionMatrix(wdbc.lda_pred, wdbc_test$diagnosis, mode = "everything")
```

The above confusion matrix indicates that the LDA model was able to correctly classify 182 instances out of 379 instances of test data. The accuracy and Kappa statistic for the model is 95.79% and 90.8% respectively.






APPLYING NAIVE BAYES:

```{r}
#install.packages('e1071')
library(e1071)
library(klaR)
set.seed(24)
naive_bayes.wdbc = train(diagnosis ~ ., data=wdbc_train, method='nb')
```

The Naive Bayes algorithm is fitted to the training data, further the outcomes of test data are predicted in the following way. 

```{r}
wdbc.nb_pred = predict(naive_bayes.wdbc, wdbc_test)
```

The model is evaluated based on the confusion matrix and other evalution metrics as shown below.

```{r}
confusionMatrix(wdbc.nb_pred, wdbc_test$diagnosis, mode = "everything")
```

The above confusion matrix indicates that the Naive Bayes model was able to correctly classify 178 instances out of 379 instances of test data. The accuracy and Kappa statistic for the model is 93.68% and 86.35% respectively.







APPLYING SVM:

```{r}
set.seed(24)
svm.wdbc = train(diagnosis ~ ., data=wdbc_train, method='svmRadial')
```

The SVM is fitted to the training data, further the outcomes of test data are predicted in the following way.

```{r}
wdbc.svm_pred = predict(svm.wdbc, newdata = wdbc_test)
```

The model is evaluated based on the confusion matrix and other evalution metrics as shown below.

```{r}
confusionMatrix(wdbc.svm_pred, wdbc_test$diagnosis, mode = "everything")
```

The above confusion matrix indicates that the SVM model was able to correctly classify 179 instances out of 379 instances of test data. The accuracy and Kappa statistic for the model is 94.21% and 87.53% respectively.







APPLYING RANDOM FOREST:

```{r}
#install.packages('randomForest')
library(randomForest)
set.seed(24)
rf.wdbc = train(diagnosis ~ ., data=wdbc_train, method='rf')
```

The Random Forest algorithm is fitted to the training data, further the outcomes of test data are predicted in the following way.

```{r}
wdbc.rf_pred = predict(rf.wdbc, newdata = wdbc_test)
```

The model is evaluated based on the confusion matrix and other evalution metrics as shown below.

```{r}
confusionMatrix(wdbc.rf_pred, wdbc_test$diagnosis, mode = "everything")
```

The above confusion matrix indicates that the Random Forest model was able to correctly classify 179 instances out of 379 instances of test data. The accuracy and Kappa statistic for the model is 94.21% and 87.38% respectively.





The four classification algorithms are compared based on their Accuracy and Kappa statistic.

```{r}
wdbc.model_comparison <- resamples(list(LDA=lda_wdbc, NB=naive_bayes.wdbc, SVM=svm.wdbc, RF=rf.wdbc))

summary(wdbc.model_comparison)
```


```{r}
scales <- list(x=list(relation="free"), y=list(relation="free"))
bwplot(wdbc.model_comparison, scales=scales)
```

It is observed from the above box-plot that the LDA is the best model in terms of Accuracy score and Kappa statistic.






```{r make a table, results='asis'}
table = matrix(NA, nrow = 4, ncol = 3)
colnames(table) = c("Models", "Accuracy", "Kappa")
table[1, ] = c("Linear Discriminant Analysis (LDA)", "95.79%", "90.8%" )
table[2, ] = c("Naive Bayes (NB)", "93.68%", "86.35%" )
table[3, ] = c("Support Vector Machine (SVM)", "94.21%", "87.53%" )
table[4, ] = c("Random Forest (RF)", "94.21%", "87.38%" )

#install.packages("kableExtra")
library(kableExtra)
kable(table, caption = "Results of Breast Cancer Wisconsin data")
```



